{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV to MARC XML Script\n",
    "Use generate_xml() to run, check out readme for full instructions. Built by UTSC's Digital Scholarship Unit.\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "This script uses the Python library Pymarc ([Link to documentation](https://pymarc.readthedocs.io/en/latest/)) to create MARC records. \n",
    "\n",
    "First, it loops through each row in the CSV, and for each row, **creates a dictionary** called *record_dict* which maps the column headers (which are the field tags) to the contents each item in the row (which are the contents of the subfields), as well as the indicators for the field. The contents are in the form of a list, since it must include both the subfield tag and the contents itself. It is refered to as the *subfield_array*. On first glance, it may seem a bit complicated, but it is a simply a dictionary in this form:\n",
    "\n",
    "```\n",
    "record_dict = {FieldTag1 : [Indicator1, Indicator2, Subfield1Tag, Subfield1Content, Subfield2Tag, Subfield2Content ....],\n",
    "               FieldTag2 : [Indicator1, Indicator2, Subfield1Tag, Subfield1Content, Subfield2Tag, Subfield2Content ....],\n",
    "               ...\n",
    "               }\n",
    "```\n",
    "               \n",
    "The record dict for simple-example.csv would be:\n",
    "```\n",
    "record_dict = {'100': ['a', 'Luke', 'b', 'Skywalker'],\n",
    "               '400': ['a', '25', 'b', 'May'],\n",
    "               '700': ['a', 'X wing']\n",
    "               }\n",
    "```\n",
    "To complicate things, any Tamil content must also be added to the MARC, and therefore must be added to the dictionary as well. The content is transliterated using the **Open-Tamil** library.\n",
    "\n",
    "After the script creates the *record_dict*, it loops through it and adds each field to the record, using Pymarc. Although it is a bit more complex in the script itself, the general idea of adding the dictionary content to the MARC looks something like this:\n",
    "```\n",
    "    for col_tag in record_dict:\n",
    "        record.add_field(\n",
    "            Field(\n",
    "                tag = tag_name,\n",
    "                indicators = record_dict[col_tag][:2],    # Indicators are first two positions\n",
    "                subfields = record_dict[col_tag][2:]      # Subfield data is the rest of the array\n",
    "            )\n",
    "        )\n",
    "```             \n",
    "Furthermore, a **leader** and a **control field** are added. \n",
    "\n",
    "Finally, it is validated using the library **lxml** and saved as an XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements \n",
    "import sys\n",
    "sys.path.append(\"/home/dsu/python_libs/open-tamil\")\n",
    "\n",
    "import csv\n",
    "import tamil\n",
    "import pandas as pd\n",
    "\n",
    "from lxml import etree\n",
    "from datetime import date\n",
    "from pymarc import XMLWriter, Record, Field\n",
    "from transliterate import azhagi, jaffna, combinational, UOM, ISO, itrans, algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up of ISO table\n",
    "ISO_table = ISO.ReverseTransliteration.table\n",
    "\n",
    "# Declare arrays to track number of record fields \n",
    "trans_field_list = []\n",
    "def_field_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that runs validation on final XML file\n",
    "\n",
    "def validate(xml_path: str, xsd_path: str) -> bool:\n",
    "    \"\"\" Returns true if the xml at\n",
    "    xml_path matches the schema at\n",
    "    xsd_path. \"\"\"\n",
    "    \n",
    "    xmlschema_doc = etree.parse(xsd_path)\n",
    "    xmlschema = etree.XMLSchema(xmlschema_doc)\n",
    "    xml_doc = etree.parse(xml_path)\n",
    "    result = xmlschema.validate(xml_doc)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the code of a subfield, for example,\n",
    "# given '100 $c | Main-entry\" it returns 'c'. \n",
    "\n",
    "def get_subfield_code(title: str) -> str:\n",
    "    \"\"\" Returns the letter code for a \n",
    "    subfield given the title of the csv\n",
    "    column. Returns 'a' if no code is\n",
    "    found. \"\"\"\n",
    "    \n",
    "    # Find index of $\n",
    "    i = title.rfind('$')\n",
    "    \n",
    "    # Return letter following $ if it exists,\n",
    "    # otherwise return 'a'\n",
    "    if i == -1:\n",
    "        return 'a'\n",
    "    else:\n",
    "        return title[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the code of a field. For instance, if\n",
    "# given '100 $c | Main-entry\" it returns '100'. \n",
    "\n",
    "def get_tag(title: str) -> str:\n",
    "    \"\"\" Returns the tag for a record\n",
    "    given the title of the csv\n",
    "    column. Returns 'None' if there\n",
    "    is no title. \"\"\"\n",
    "    \n",
    "    # Check if title exists\n",
    "    if title == 'nan':\n",
    "        # Return 'None' if none exists\n",
    "        return \"None\"\n",
    "    else:\n",
    "        # If title is found, get indexes of\n",
    "        # first space and slash\n",
    "        i = title.find(' ')\n",
    "        j = title.find('/')\n",
    "        \n",
    "        # If no space and no slash is found\n",
    "        if i == -1 and j == -1:\n",
    "            # Return the entire title\n",
    "            return title\n",
    "        # If no space and a slash is found\n",
    "        elif i == -1 and j != -1:\n",
    "            # Return value up to slash\n",
    "            return title[:j]\n",
    "        # Otherwise there is a space\n",
    "        else:\n",
    "            # Return tag up to space\n",
    "            return title[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Tamil transliteration\n",
    "\n",
    "def get_transliterated(content: str) -> str:\n",
    "    \"\"\" Returns the transliterated\n",
    "    content string with ISO 15919. \"\"\"\n",
    "    \n",
    "    # Use open-tamil algorithim to transliterate\n",
    "    return algorithm.Direct.transliterate(ISO_table, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets the subfield array for a column.\n",
    "\n",
    "def get_subfield_array(content: str, category: str, title: str, key: str) -> list:\n",
    "    \"\"\" Returns an array with subfield codes and data,\n",
    "    given the column category, title, key and cell\n",
    "    content. Tamil content will be transliterated.\n",
    "    If no content exists, or is '---', returns an \n",
    "    empty list.\"\"\"\n",
    "    \n",
    "    subfield_array = []\n",
    "    \n",
    "    # Check if content exists\n",
    "    if ('---' in content) or (content == 'nan'):\n",
    "        # If it does not exist, return no subfields\n",
    "        return subfield_array\n",
    "\n",
    "    # Get subfield code\n",
    "    sub_code = get_subfield_code(title)\n",
    "\n",
    "    # Check if content is in Tamil\n",
    "    if \"(Tamil)\" in category:\n",
    "        # Find number of corresponding transliteration subfield\n",
    "        if key in def_field_list or key == 'None':\n",
    "            trans_count = len(def_field_list)\n",
    "        else:\n",
    "            def_field_list.append(key)\n",
    "            trans_count = len(def_field_list)\n",
    "\n",
    "        # Add a '0' if number is single digit\n",
    "        if trans_count < 10: num = '0' + str(trans_count)\n",
    "        else: num = str(trans_count)\n",
    "\n",
    "        # Construct subfield array with Tamil specifications, including transliterated content\n",
    "        subfield_array = [\"6\", \"880-\" + num, sub_code, get_transliterated(content)]\n",
    "    else:\n",
    "        # Construct subfield array without Tamil specifications\n",
    "        subfield_array = [sub_code, content]\n",
    "    \n",
    "    return subfield_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns a subfield array for a Tamil column\n",
    "\n",
    "def get_trans_subfield_array(content: str, category: str, title: str, key: str) -> list:\n",
    "    \"\"\" Returns an array with subfield codes\n",
    "    and data, given the column category, title,\n",
    "    key, and cell content for a Tamil column. \n",
    "    If no content exists, or is '---', returns \n",
    "    an empty list.\"\"\"\n",
    "    \n",
    "    subfield_array = []\n",
    "    \n",
    "    # Check if content exists\n",
    "    if ('---' in content) or (content == 'nan'):\n",
    "        # If it does not exist, return no subfields\n",
    "        return subfield_array\n",
    "    \n",
    "    # Get subfield code\n",
    "    sub_code = get_subfield_code(title)\n",
    "\n",
    "    if \"(Tamil)\" in category:\n",
    "        # Find number of corresponding transliteration subfield\n",
    "        if key in trans_field_list or key == 'None':\n",
    "            trans_count = len(trans_field_list)\n",
    "        else:\n",
    "            trans_field_list.append(key)\n",
    "            trans_count = len(trans_field_list)\n",
    "\n",
    "        # Add a '0' if number is single digit\n",
    "        if trans_count < 10: num = '0' + str(trans_count)\n",
    "        else: num = str(trans_count)\n",
    "            \n",
    "        # Construct subfield array with Tamil specifications, including untransliterated content\n",
    "        subfield_array = [\"6\", key + \"-\" + num, sub_code, content]\n",
    "    else:\n",
    "        # Construct subfield array without Tamil specifications (should never be called)\n",
    "        subfield_array = [sub_code, content]\n",
    "    \n",
    "    return subfield_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function handles getting string of 008 controlfield\n",
    "\n",
    "def get_control_field(record_dict: dict) -> str:\n",
    "    \"\"\" Given record_dict, returns a string\n",
    "    for the control field 008. \"\"\"\n",
    "    \n",
    "    data_str = \"\"\n",
    "    \n",
    "    # Check if date can be found\n",
    "    if '260' in record_dict:\n",
    "        if 'c' in record_dict['260']:            \n",
    "            # Get date of publication, which follows the 'c' subfield in field 260\n",
    "            i = record_dict['260'].index('c')\n",
    "            pub_date = record_dict['260'][i+1]\n",
    "            \n",
    "            # Get the date entered (presumed the date created)\n",
    "            today = str(date.today())\n",
    "            year = today[:4]\n",
    "            month = today[5:7]\n",
    "            \n",
    "            # Add to data string, as well as including language and type of publication\n",
    "            data_str = year + month + \"s\" + pub_date + \"    ii a          000 0 tam d\"\n",
    "    \n",
    "    return data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inds(category, csv_data) -> list:\n",
    "    \"\"\" Returns a list of indicators\n",
    "    for the category in csv_data. \"\"\"\n",
    "    \n",
    "    ind_list = []\n",
    "    data = csv_data[category][1]\n",
    "    if data == data:\n",
    "        ind_list = [data[0], data[2]]\n",
    "        \n",
    "    for i in range(len(ind_list)):\n",
    "        if ind_list[i] == '_':\n",
    "            ind_list[i] = ' '\n",
    "    \n",
    "    return ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function responsible for returning the record_dict for each record\n",
    "\n",
    "def get_record_dict(row, csv_data) -> dict:\n",
    "    \"\"\"Returns a dictionary mapping record tags\n",
    "    to the subfield arrays, given a row of the \n",
    "    csv_data.\"\"\"\n",
    "    \n",
    "    record_dict = {}\n",
    "    \n",
    "    # Loop through each column\n",
    "    for category, col in csv_data.iteritems():         \n",
    "        # Get title, content, and tag for each field\n",
    "        title = str(col[0])\n",
    "        content = str(row[category])\n",
    "        raw_key = get_tag(title)\n",
    "        inds = get_inds(category, csv_data)\n",
    "        \n",
    "        # Create subfield arrary\n",
    "        sub_array = get_subfield_array(content, category, title, raw_key)\n",
    "\n",
    "        # Check if field can be added to dictionary\n",
    "        if raw_key != 'None' and content != 'nan' and content != '---':\n",
    "            key = str(int(float(raw_key)))\n",
    "            # Check if tag is already in dictionary\n",
    "            if key in record_dict:\n",
    "                # If tag is in dictionary, check if it has a Tamil component\n",
    "                if \"6\" in record_dict[key] and len(sub_array) == 4:\n",
    "                    # If it has a Tamil component, ignore the '6' subfield (already present, would be a duplicate)\n",
    "                    record_dict[key] = record_dict[key] + sub_array[2:]\n",
    "                else:\n",
    "                    # If it does has a Tamil component, add entire subfield array\n",
    "                    record_dict[key] = record_dict[key] + sub_array\n",
    "            else:\n",
    "                # If tag is not in dictionary, add subfield array to dictionary\n",
    "                record_dict[key] = inds + sub_array\n",
    "                \n",
    "            if \"(Tamil)\" in category:\n",
    "                sub_array = get_trans_subfield_array(content, category, title, key)\n",
    "                trans_count = len(trans_field_list)\n",
    "                # Check if tag exists\n",
    "                if key != 'None' and len(sub_array) > 0:\n",
    "                    # Check if tag is already in dictionary\n",
    "                    if \"880-\" + str(trans_count) in record_dict:\n",
    "                        # If tag is in dictionary, update subfield array\n",
    "                        record_dict['880-' + str(trans_count)] = record_dict['880-' + str(trans_count)] + sub_array[2:]\n",
    "                    else:\n",
    "                        # If tag is not in dictionary, add subfield array to dictionary\n",
    "                        record_dict['880-' + str(trans_count)] = inds + sub_array\n",
    "                        \n",
    "    return record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_duplicate(category: str, tag: str):\n",
    "    \"\"\" Returns true if category can be removed\n",
    "    in order to avoid duplicate fields to abide\n",
    "    by MARC rules.\"\"\"\n",
    "    \n",
    "    # Check if it has been manually transliterated\n",
    "    if '(English)' in category or 'General note' in category:\n",
    "        # Check if in no-duplicate field/subfield\n",
    "        blocked_fields = ['100', '245', '250', '500']\n",
    "        num = get_tag(tag)\n",
    "        if num in blocked_fields and 'a' in tag:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function block\n",
    "\n",
    "def generate_xml(outputname: str, inputname: str) -> None:\n",
    "    \"\"\"Generates MARC xml file from csv file with\n",
    "    name inputname, using the pymarc library. Output\n",
    "    is named with outputname. \"\"\"\n",
    "    \n",
    "    csv_data = pd.read_csv(inputname)\n",
    "    for category, col in csv_data.iteritems(): \n",
    "        if col[0] == col[0] and is_duplicate(category, col[0]):\n",
    "            csv_data = csv_data.drop(category, 1)\n",
    "    \n",
    "    writer = XMLWriter(open(outputname + '.xml','wb'))\n",
    "    \n",
    "    # Loop through rows (records) of csv\n",
    "    for i, row in csv_data.iterrows():\n",
    "        # Skip first row (title row)\n",
    "        if i >= 2:            \n",
    "            # Clear out transliteration tracking arrays\n",
    "            def_field_list.clear()\n",
    "            trans_field_list.clear()\n",
    "            \n",
    "            # Create new record and get dictionaries\n",
    "            leader_str = \"00000cam a2200000Ma 4500\"\n",
    "            record = Record(leader=leader_str)\n",
    "            record_dict = get_record_dict(row, csv_data)\n",
    "            \n",
    "            # Add 008 controlfield\n",
    "            data_str = get_control_field(record_dict) \n",
    "            field = Field(tag='008', data=data_str)\n",
    "            record.add_field(field)\n",
    "            \n",
    "            # Get indicators\n",
    "            #ind_list = get_ind_list(csv_data)\n",
    "\n",
    "            # Loop through tags in dictionary\n",
    "            for col_tag in record_dict:\n",
    "                if '880-' in col_tag: tag_name = '880'\n",
    "                else: tag_name = col_tag\n",
    "                # Add record to XML\n",
    "                record.add_field(\n",
    "                    Field(\n",
    "                         tag = tag_name,\n",
    "                         indicators = record_dict[col_tag][:2],\n",
    "                         subfields = record_dict[col_tag][2:]\n",
    "                    )\n",
    "                )\n",
    "           \n",
    "            # Write record to XML\n",
    "            writer.write(record)\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "    # Validate output\n",
    "    if validate(outputname + \".xml\", \"MARC21slim.xsd\"):\n",
    "        print(\"[MARC Record saved]\")\n",
    "    else:\n",
    "        print('[WARNING: not valid.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run script on simple-example.csv with output files named 'OUTPUT'\n",
    "generate_xml(\"OUTPUT\", \"TestRecords_MARCxml.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
